# TechNova Compensation & Market Benchmarking Dashboard

**Portfolio Project S2 | Hadi Mercer | BA Portfolio 2026**

A full-stack data pipeline and interactive dashboard that pulls real wage data from the Bureau of Labor Statistics, stores it alongside internal job grade data in PostgreSQL, and surfaces compensation benchmarking gaps and pay equity flags through a live Streamlit web application.

> TechNova is a realistic fictional healthcare technology company created for portfolio demonstration. All employee data, salary figures, and organizational details are synthetic.

---

## Live Demo

ğŸ”— **Dashboard**: [Coming â€” deploying to Streamlit Community Cloud]
ğŸ“ **Portfolio Hub**: [hadimercer.github.io](https://hadimercer.github.io)

---

## What This Project Demonstrates

| Capability | Evidence |
|---|---|
| Business Analysis | BABOK v3-aligned FRD with MoSCoW prioritization, stakeholder map, traceability matrix |
| Data Engineering | Python pipeline: API ingestion, CSV validation, PostgreSQL loading, audit logging |
| API Integration | BLS OEWS REST API â€” 600 series/run, batched requests, error handling |
| Database Design | PostgreSQL schema with 8 tables, FK constraints, indexes, unique constraints |
| Data Modeling | Job-to-SOC crosswalk with match quality metadata across 38 role mappings |
| Visualization | Streamlit dashboard: benchmarking view, below-market flags, pay equity module |
| Documentation | OpenAPI/Swagger spec, UML sequence diagram, data dictionary |
| Security | Environment variable credential management, no hardcoded secrets |

---

## Project Architecture

```
BLS Public API (OEWS)
        â”‚
        â–¼
pipeline/bls_pipeline.py
  â”œâ”€â”€ Reads SOC codes from DB
  â”œâ”€â”€ Builds 600 series IDs (5 MSAs Ã— 20 SOC codes Ã— 6 data types)
  â”œâ”€â”€ Batches API calls (50/request, 0.5s delay)
  â””â”€â”€ Loads â†’ bls_wage_data table
        â”‚
data/ CSVs (employees + job grades)
        â”‚
        â–¼
pipeline/csv_ingestion.py
  â”œâ”€â”€ Schema validation (rejects entire file on failure)
  â”œâ”€â”€ Type coercion + null handling
  â””â”€â”€ Upserts â†’ employees + internal_job_grades tables
        â”‚
pipeline/seed_reference_data.py
  â””â”€â”€ Seeds â†’ soc_code_reference + job_soc_crosswalk tables
        â”‚
        â–¼
PostgreSQL (Supabase)
  â”œâ”€â”€ employees (800 rows)
  â”œâ”€â”€ internal_job_grades (150 rows)
  â”œâ”€â”€ bls_wage_data (100 rows, 2024 OEWS)
  â”œâ”€â”€ soc_code_reference (20 SOC codes)
  â”œâ”€â”€ job_soc_crosswalk (38 role mappings)
  â”œâ”€â”€ pipeline_run_log (audit trail)
  â”œâ”€â”€ crosswalk_change_log (controlled artifact history)
  â””â”€â”€ job_families (lookup)
        â”‚
        â–¼
Streamlit Dashboard (app.py)
  â”œâ”€â”€ Page 1: Benchmarking View (filter â†’ market range)
  â”œâ”€â”€ Page 2: Below-Market Flags
  â””â”€â”€ Page 3: Pay Equity Module (gender gaps)
```

---

## Repository Structure

```
comp-benchmarking/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ technova_employees.csv      # 800 synthetic employees
â”‚   â””â”€â”€ technova_job_grades.csv     # 150 job grade band definitions
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ TechNova_FRD_COMP001.docx   # BABOK-aligned FRD
â”‚   â”œâ”€â”€ TechNova_SOC_Crosswalk_XWALK001.xlsx  # SOC mapping artifact
â”‚   â”œâ”€â”€ openapi_bls_integration.yaml  # OpenAPI/Swagger spec (coming)
â”‚   â””â”€â”€ uml_sequence_diagram.png      # Data flow diagram (coming)
â”œâ”€â”€ logs/                           # Pipeline run logs (git-ignored)
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ csv_ingestion.py            # CSV â†’ PostgreSQL loader
â”‚   â”œâ”€â”€ seed_reference_data.py      # SOC codes + crosswalk seeder
â”‚   â””â”€â”€ bls_pipeline.py             # BLS API â†’ PostgreSQL pipeline
â”œâ”€â”€ app.py                          # Streamlit dashboard (coming)
â”œâ”€â”€ .env                            # Credentials (git-ignored)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ CLAUDE.md                       # Project memory for AI coding sessions
â”œâ”€â”€ README.md                       # This file
â””â”€â”€ requirements.txt                # Python dependencies (coming)
```

---

## Setup Instructions

### Prerequisites
- Python 3.9+
- A free [Supabase](https://supabase.com) account
- A free [BLS API registration key](https://data.bls.gov/registrationEngine)

### 1. Clone the repository
```bash
git clone https://github.com/hadimercer/comp-benchmarking.git
cd comp-benchmarking
```

### 2. Install dependencies
```bash
python -m pip install streamlit psycopg2-binary python-dotenv pandas requests plotly
```

### 3. Set up the database
Create a new Supabase project, then paste the contents of `docs/schema.sql` into the Supabase SQL Editor and run it. This creates all 8 tables.

### 4. Configure environment variables
Copy `.env.example` to `.env` and fill in your values:
```
DB_HOST=aws-1-us-east-1.pooler.supabase.com
DB_PORT=5432
DB_NAME=postgres
DB_USER=postgres.[your-project-ref]
DB_PASSWORD=[your-supabase-password]
BLS_API_BASE_URL=https://api.bls.gov/publicAPI/v2
BLS_REGISTRATION_KEY=[your-bls-key]
BLS_SURVEY_YEAR=2024
DATA_DIR=./data
LOG_DIR=./logs
```

### 5. Run the pipelines in order
```bash
# Load internal data
python -m pipeline.csv_ingestion

# Seed SOC reference data and crosswalk
python -m pipeline.seed_reference_data

# Pull BLS wage data
python -m pipeline.bls_pipeline
```

### 6. Launch the dashboard
```bash
python -m streamlit run app.py
```

---

## Data Pipeline Detail

### BLS OEWS Series ID Format
The BLS OEWS API uses a 25-character series identifier:

```
O  E  U  M  0  0  1  9  7  4  0  0  0  0  0  0  0  1  5  1  2  5  2  0  3
1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25
|prefix| adj|type|----area code----|----industry----|---occupation---|dtype|
  OE    U    M    0019740            000000            151252          03
```

| Position | Value | Meaning |
|---|---|---|
| 1-2 | `OE` | OEWS prefix |
| 3 | `U` | Unadjusted (seasonal) |
| 4 | `M` | MSA area type |
| 5-11 | `0019740` | Denver MSA code, zero-padded to 7 digits |
| 12-17 | `000000` | All industries |
| 18-23 | `151252` | SOC code digits, no dash, zero-padded to 6 |
| 24-25 | `03` | Annual mean wage |

**Data type codes**: `03`=mean, `11`=P10, `12`=P25, `13`=P50, `14`=P75, `15`=P90

### The 5 TechNova MSAs
Austin TX (12420) Â· New York NY (35620) Â· San Francisco CA (41860) Â· Washington DC (47900) Â· Denver CO (19740)

### The 20 SOC Codes
Covers all TechNova job families: Software Engineering, Data & Analytics, Product Management, Clinical Informatics/Health IT, UX/Design, DevOps/Platform/SRE, IT/Systems Administration, Sales & Account Management, Corporate.

---

## Functional Requirements Coverage

| ID | Requirement | Status |
|---|---|---|
| FR-01 | BLS API pull â€” wage percentiles + MSA filter | âœ… Done |
| FR-02 | Quarterly manual trigger, documented run procedure | âœ… Done |
| FR-03 | Pipeline run log â€” timestamp + record count + status | âœ… Done |
| FR-04 | Schema change + HTTP error detection | âœ… Done |
| FR-05 | CSV flat file load to PostgreSQL | âœ… Done |
| FR-06 | Schema validation before write | âœ… Done |
| FR-07 | Documented CSV template | âœ… Done |
| FR-08 | Job-to-SOC crosswalk table | âœ… Done |
| FR-09 | MSA-level geographic wage storage | âœ… Done |
| FR-10 | Full data dictionary | âœ… Done (Excel artifact) |
| FR-11 | Dashboard: filter â†’ market range | ğŸ”² In progress |
| FR-12 | Dashboard: internal vs market side-by-side | ğŸ”² In progress |
| FR-13 | Dashboard: percentile toggle P25/P50/P75 | ğŸ”² In progress |
| FR-14 | Dashboard: below-market flags view | ğŸ”² In progress |
| FR-15 | Dashboard: pay equity gap flags (gender) | ğŸ”² In progress |
| FR-16 | Dashboard: data freshness indicator | ğŸ”² In progress |
| FR-17 | OpenAPI/Swagger spec for BLS integration | ğŸ”² Queued |
| FR-18 | UML sequence diagram â€” end-to-end data flow | ğŸ”² Queued |

---

## Key Design Decisions

**Streamlit over Power BI**: Power BI Service requires a Pro license ($10/mo) for public report sharing â€” which creates an access wall for portfolio reviewers. Streamlit Community Cloud is free, produces a public URL instantly, and is Python-native.

**Session pooler over direct Supabase connection**: The direct `db.[ref].supabase.co` host failed DNS resolution on Windows. Supabase's session pooler (`aws-1-us-east-1.pooler.supabase.com`) works reliably and supports full transaction semantics needed for our rollback logic.

**BLS OEWS only (no commercial surveys)**: Radford, Mercer, and WTW data requires paid licenses. BLS OEWS is public, annually refreshed, and sufficient for portfolio demonstration. SOC-level aggregation limitations are documented in the crosswalk and surfaced in the dashboard.

**Fail loudly on validation**: The pipeline rejects the entire CSV file if any validation rule fails â€” no silent partial loads. This is a non-negotiable data quality standard for a compensation system where decisions are made against the data.

**SRE mapped to 15-1252 (Software Developers), not 15-1244 (Network/SysAdmin)**: SRE roles are intentionally split from DevOps because SRE work is software-heavy by task definition. This is a documented crosswalk decision (XW-021).

---

## Portfolio Context

This is **Smaller Project 2 (S2)** of a 6-project BA portfolio:

| # | Project | Focus |
|---|---|---|
| F1 | Operational Process Intelligence | What-if simulation |
| F2 | BA Co-Pilot | AI-powered artifact generation |
| S1 | HR Process Automation Hub | Workflow automation |
| **S2** | **Comp & Benchmarking Dashboard** | **â† This project** |
| S3 | Program Portfolio Dashboard | RAG status health view |
| S4 | Sentiment & Text Analytics | NLP analysis |

---

## Contact

**Hadi Mercer**
LinkedIn: [linkedin.com/in/hadimercer](https://linkedin.com/in/hadimercer)
GitHub: [github.com/hadimercer](https://github.com/hadimercer)
